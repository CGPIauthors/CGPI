{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83faf2bc-0323-45ab-8ccb-49f9139115a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Misc. setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3af863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ipynb_dir = globals()['_dh'][0]\n",
    "main_dir = os.path.join(ipynb_dir, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722834a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bafa2-c5df-4067-85c8-4827d1803bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddcac01-705b-4a64-996e-0aa642e030f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924e123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rcParams['figure.figsize'] = (60, 60)\n",
    "#plt.rcParams['font.size'] = 80\n",
    "plt.rcParams['figure.dpi'] = 40\n",
    "#matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "#matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c63c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42     # use true-type\n",
    "mpl.rcParams['ps.fonttype'] = 42      # use true-type\n",
    "mpl.rcParams['font.size'] = 12\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22027a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0f1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from test_scripts.train_reacher_usfa import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a3bbe-354e-4fbb-bb91-572fd08d30ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameters and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f665984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = get_hyperparameters({}, args=[\n",
    "    '--device', 'cpu',\n",
    "    '--run_group', 'jupyter',\n",
    "    '--seed', '1',\n",
    "    '--test_exploration', '0.0',\n",
    "    '--num_test_episodes', '10',\n",
    "])\n",
    "\n",
    "load_caches_only = False\n",
    "\n",
    "use_deterministic_transition_with_salts = True\n",
    "\n",
    "#common_sort_key = 'avg. return'\n",
    "common_sort_key = 'avg. undiscounted_return'\n",
    "\n",
    "verbose_print = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5a6ad-9e6a-48c6-8c8d-4cd4ccf812fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "target_task_vecs_spec = 'PN2T1'\n",
    "target_task_xys = sorted([\n",
    "    list(t)\n",
    "    for t in itertools.product(*[[-1.0, 1.0] for _ in range(4)])\n",
    "])\n",
    "\n",
    "target_task_xys_np = np.asarray(target_task_xys)\n",
    "\n",
    "target_task_vecs = ReacherWrappedEnv.convert_target_info_to_task_vec(\n",
    "    torch.as_tensor(target_task_xys, dtype=torch.float64),\n",
    "    phi_type='neg_dists_to_source_xys',\n",
    ").tolist()\n",
    "\n",
    "print(str(target_task_vecs).replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11291b-c76f-4f26-aa93-e2bc87601398",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_target_task_vecs_filters_np = dict()\n",
    "all_target_task_vecs_filters_np['all'] = np.ones_like(np.asarray(target_task_vecs)[:, 0], dtype=bool)\n",
    "all_target_task_vecs_filters_np['equal_or_more_negatives'] = (np.asarray(target_task_vecs).sum(axis=-1) <= 1e-5)\n",
    "\n",
    "target_task_vecs_filter_np = all_target_task_vecs_filters_np['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342ec40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "psi_ckpts_infos_test = [\n",
    "    dict(\n",
    "        name='Reacher',\n",
    "        paths=[\n",
    "            r'/path/to/your/expdir1/psi_001000000.pt',\n",
    "            r'/path/to/your/expdir2/psi_001000000.pt',\n",
    "            r'/path/to/your/expdir3/psi_001000000.pt',\n",
    "            r'/path/to/your/expdir4/psi_001000000.pt',\n",
    "            r'/path/to/your/expdir5/psi_001000000.pt',\n",
    "            r'/path/to/your/expdir6/psi_001000000.pt',\n",
    "            r'/path/to/your/expdir7/psi_001000000.pt',\n",
    "            r'/path/to/your/expdir8/psi_001000000.pt',\n",
    "        ],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2734148-ab1b-4745-baa9-846663ceeaa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Defining functions and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12272f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_utils.set_seed(hyperparameters['seed'])\n",
    "ReacherTaskPresets._device = hyperparameters['device']\n",
    "ReacherTaskPresets._reacher_hyperparameters = hyperparameters['reacher']\n",
    "ReacherTaskPresets._usfa_con_hyperparameters = hyperparameters['usfa_constraints']\n",
    "\n",
    "reacher_hps = exp_utils.AttributeDict(copy.copy(dict(hyperparameters['reacher'])))\n",
    "reacher_hps['task_vec_sampler'] = getattr(\n",
    "    ReacherTaskPresets, reacher_hps['task_preset']).test_task_vec_sampler\n",
    "reacher_hps['source_xys'] = getattr(\n",
    "    ReacherTaskPresets, reacher_hps['task_preset']).source_xys()\n",
    "\n",
    "for v in getattr(ReacherTaskPresets, reacher_hps['task_preset']).train_task_vecs():\n",
    "    assert v.size(0) == getattr(\n",
    "        ReacherTaskPresets, reacher_hps['task_preset']).get_task_vec_dim()\n",
    "for v in getattr(ReacherTaskPresets, reacher_hps['task_preset']).test_task_vecs():\n",
    "    assert v.size(0) == getattr(\n",
    "        ReacherTaskPresets, reacher_hps['task_preset']).get_task_vec_dim()\n",
    "\n",
    "task_preset = reacher_hps['task_preset']\n",
    "del reacher_hps['task_preset']\n",
    "\n",
    "env = ReacherWrappedEnv(\n",
    "    **reacher_hps,\n",
    "    device=hyperparameters['device'],\n",
    ")\n",
    "\n",
    "preset_builder = PresetBuilder(\n",
    "    'usfa',\n",
    "    { 'hyperparameters': hyperparameters },\n",
    "    USFAReacherPreset,\n",
    "    device=hyperparameters['device'],\n",
    "    env=env)\n",
    "preset = preset_builder.build()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53748c2b-0d96-442c-b79d-f64587f3f171",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for info in psi_ckpts_infos_test:\n",
    "    info['source_task_vecs'] = getattr(ReacherTaskPresets, task_preset).train_task_vecs()\n",
    "    info['source_xys'] = getattr(ReacherTaskPresets, task_preset).source_xys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822667b-0e9c-4616-bb10-5fabccd669f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def construct_env_for_specific_task_vec(task_vec, env_kwargs=dict()):\n",
    "    def _sampler():\n",
    "        return task_vec\n",
    "    hps = exp_utils.AttributeDict(copy.copy(dict(reacher_hps)))\n",
    "    hps['task_vec_sampler'] = _sampler\n",
    "    assert 'source_xys' in env_kwargs\n",
    "    return ReacherWrappedEnv(\n",
    "        **dict(\n",
    "            hps,\n",
    "            **env_kwargs,\n",
    "        ),\n",
    "        device=hyperparameters['device'],\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def _sort_key(path):\n",
    "    return tuple(reversed(os.path.split(path)))\n",
    "    \n",
    "def ensure_file(path):\n",
    "    if os.path.exists(path):\n",
    "        if verbose_print:\n",
    "            print(path)\n",
    "        return path\n",
    "    g = sorted(glob.glob(path), key=_sort_key)\n",
    "    #assert len(g) == 1\n",
    "    if verbose_print:\n",
    "        print(g[-1])\n",
    "    return g[-1]\n",
    "\n",
    "def load_usfa_net(path):\n",
    "    psi_module = torch.load(\n",
    "        ensure_file(path),\n",
    "        map_location=hyperparameters['device'])\n",
    "    return USFAPsiNetwork(\n",
    "        model=psi_module,\n",
    "        action_dim=preset.n_actions,\n",
    "        task_vec_dim=preset.env.get_task_vec_dim(),\n",
    "        normalize_policy_vecs=hyperparameters['normalize_policy_vecs'],\n",
    "        ensemble_reduction_info=dict(\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e0ebdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_test_agent_from_psi(psi,\n",
    "                                  default_gpi_source_policy_vecs=torch.zeros((0, preset.env.get_task_vec_dim()), device=hyperparameters['device']),\n",
    "                                  include_target_task_vec_for_gpi=True,\n",
    "                                  epsilon=hyperparameters['test_exploration'],\n",
    "                                  gpi_q_network_kwargs=dict(q_ensemble_reduction='mean')):\n",
    "    gpi_q = psi.construct_gpi_q_network(**gpi_q_network_kwargs)\n",
    "    gpi_policy = GreedyPolicy(gpi_q, preset.n_actions, epsilon=epsilon)\n",
    "    return USFATestAgent(\n",
    "        gpi_policy=gpi_policy,\n",
    "        default_gpi_source_policy_vecs=default_gpi_source_policy_vecs,\n",
    "        include_target_task_vec_for_gpi=include_target_task_vec_for_gpi,\n",
    "    )\n",
    "\n",
    "def construct_test_agent_from_ckpt(path, *args, **kwargs):\n",
    "    psi = load_usfa_net(path)\n",
    "    return construct_test_agent_from_psi(psi, *args, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d696b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from all.core.state import State, StateArray\n",
    "from alli.core.state_util import compute_returns\n",
    "\n",
    "def _collect_states_from_single_rollout(env, test_agent):\n",
    "    #time_start = time.time()\n",
    "\n",
    "    states = []\n",
    "    # initialize the episode\n",
    "    states.append(env.reset())\n",
    "    action = test_agent.act(states[-1])\n",
    "\n",
    "    # loop until the episode is finished\n",
    "    while not states[-1].done:\n",
    "        states.append(env.step(action))\n",
    "        action = test_agent.act(states[-1])\n",
    "\n",
    "    #time_end = time.time()\n",
    "    #print(f'fps: {len(states) / (time_end - time_start)}, len: {len(states)}')\n",
    "        \n",
    "    return State.array(states)\n",
    "    \n",
    "def collect_states_with_generator(envs_generator, test_agent, post_rollout_callbacks=[]):\n",
    "    all_states = []\n",
    "    for env in envs_generator:\n",
    "        all_states.append(_collect_states_from_single_rollout(env=env, test_agent=test_agent))\n",
    "        for cb in post_rollout_callbacks:\n",
    "            cb(env, test_agent, all_states[-1])\n",
    "    all_states = State.array(all_states)\n",
    "    all_states['return'] = compute_returns(\n",
    "        all_states,\n",
    "        hyperparameters['discount_factor'],\n",
    "        dim=1)\n",
    "    all_states['undiscounted_return'] = compute_returns(\n",
    "        all_states,\n",
    "        1.0,\n",
    "        dim=1)\n",
    "    return all_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691777f-c030-45c7-a295-904c7f5634df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from alli.core.state_util import apply_slices\n",
    "\n",
    "def collect_states_on_target_tasks(\n",
    "    psi_info,\n",
    "    path,\n",
    "    gpi_type,\n",
    "    num_test_episodes,\n",
    "    *,\n",
    "    use_deterministic_transition_with_salts: bool,\n",
    "    get_test_agent=None,\n",
    "    target_task_vecs=target_task_vecs,\n",
    "    post_rollout_callbacks=[],\n",
    "):\n",
    "    assert gpi_type in ['target', 'source', 'source + target']\n",
    "    psi = load_usfa_net(path)\n",
    "    source_task_vecs = psi_info['source_task_vecs']\n",
    "    \n",
    "    def _get_test_agent(t):\n",
    "        if gpi_type == 'target':\n",
    "            default_gpi_source_policy_vecs = torch.as_tensor([t], device=hyperparameters['device'])\n",
    "        elif gpi_type == 'source':\n",
    "            default_gpi_source_policy_vecs = source_task_vecs\n",
    "        elif gpi_type == 'source + target':\n",
    "            default_gpi_source_policy_vecs = torch.cat([\n",
    "                source_task_vecs,\n",
    "                torch.as_tensor([t], device=hyperparameters['device']),\n",
    "            ], dim=0)\n",
    "        else:\n",
    "            assert False\n",
    "        return construct_test_agent_from_psi(\n",
    "            psi,\n",
    "            default_gpi_source_policy_vecs=default_gpi_source_policy_vecs,\n",
    "            include_target_task_vec_for_gpi=False,\n",
    "        )\n",
    "    \n",
    "    if get_test_agent is None:\n",
    "        get_test_agent = _get_test_agent\n",
    "\n",
    "    def _envs_generator(t):\n",
    "        for idx in range(num_test_episodes):\n",
    "            if use_deterministic_transition_with_salts:\n",
    "                yield construct_env_for_specific_task_vec(\n",
    "                    torch.as_tensor([t], device=hyperparameters['device']),\n",
    "                    dict(\n",
    "                        env_specific_random_seed=idx,\n",
    "                        source_xys=psi_info['source_xys'],\n",
    "                    ),\n",
    "                )\n",
    "            else:\n",
    "                yield construct_env_for_specific_task_vec(\n",
    "                    torch.as_tensor([t], device=hyperparameters['device']),\n",
    "                    dict(\n",
    "                        source_xys=psi_info['source_xys'],\n",
    "                    ),\n",
    "                )\n",
    "    \n",
    "    return [\n",
    "        collect_states_with_generator(\n",
    "            envs_generator=_envs_generator(t),\n",
    "            test_agent=get_test_agent(t),\n",
    "            post_rollout_callbacks=post_rollout_callbacks,\n",
    "        )\n",
    "        for t in target_task_vecs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a65ae",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07799fb-e1bc-4124-bf6d-f92093cd903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import hashlib\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import cloudpickle\n",
    "\n",
    "def pickle_dumps(obj):\n",
    "    try:\n",
    "        return pickle.dumps(obj)\n",
    "    except (pickle.PicklingError, AttributeError) as e:\n",
    "        return cloudpickle.dumps(obj)\n",
    "\n",
    "def get_cache_ex_json_file_path(psi_info, path, name, setting_name, hyp, dir_name_suffix=''):\n",
    "    cache_dir_name = f'ipynbs/cache.eval_perf_stats_ex_json_reacher{dir_name_suffix}'\n",
    "    try:\n",
    "        os.makedirs(cache_dir_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if callable(path):\n",
    "        path = path()\n",
    "\n",
    "    path_identifier = os.path.basename(os.path.dirname(path)) + os.path.sep + os.path.basename(path)\n",
    "\n",
    "    filename = (\n",
    "        name + '__' +\n",
    "        hashlib.md5(str.encode(path_identifier)).hexdigest() + '__' +\n",
    "        setting_name + '__' +\n",
    "        hashlib.md5(pickle_dumps(hyp)).hexdigest() +\n",
    "        '.json'\n",
    "    )\n",
    "\n",
    "    if verbose_print:\n",
    "        print(path_identifier, '->', hashlib.md5(str.encode(path_identifier)).hexdigest())\n",
    "        print(hyp, '->', hashlib.md5(pickle_dumps(hyp)).hexdigest())\n",
    "\n",
    "    assert len(filename) <= os.pathconf('/', 'PC_NAME_MAX'), filename\n",
    "    \n",
    "    if verbose_print:\n",
    "        print(filename)\n",
    "\n",
    "    return os.path.join(\n",
    "        cache_dir_name,\n",
    "        filename)\n",
    "\n",
    "def read_cache_ex_json(psi_info, path, name, setting_name, hyp, **kwargs):\n",
    "    cache_path = get_cache_ex_json_file_path(psi_info, path, name, setting_name, hyp, **kwargs)\n",
    "    if not os.path.exists(cache_path):\n",
    "        return None\n",
    "    with open(cache_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_cache_ex_json(psi_info, path, name, setting_name, hyp, data, **kwargs):\n",
    "    cache_path = get_cache_ex_json_file_path(psi_info, path, name, setting_name, hyp, **kwargs)\n",
    "    with open(cache_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5872a-c077-4957-8c5f-c31911752ac3",
   "metadata": {},
   "source": [
    "# Perf stat-related definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74d168-0eca-4aed-8503-bce5183fcf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perf_stats_with_gpi_options(\n",
    "        psi_info_test,\n",
    "        psi,\n",
    "        t,\n",
    "        *,\n",
    "        num_test_episodes,\n",
    "        use_deterministic_transition_with_salts: bool,\n",
    "        source_task_vecs=None,\n",
    "        include_target_task_vec_for_gpi=False,\n",
    "        gpi_q_network_kwargs=dict(q_ensemble_reduction='mean'),\n",
    "        post_rollout_callbacks=[],\n",
    "    ):\n",
    "\n",
    "    if source_task_vecs is None:\n",
    "        source_task_vecs = psi_info_test['source_task_vecs']\n",
    "    target_task_vecs_test = torch.as_tensor([t], device=hyperparameters['device'])\n",
    "    \n",
    "    gpi_source_policy_vecs = source_task_vecs\n",
    "    test_agent = construct_test_agent_from_psi(\n",
    "        psi,\n",
    "        default_gpi_source_policy_vecs=gpi_source_policy_vecs,\n",
    "        include_target_task_vec_for_gpi=include_target_task_vec_for_gpi,\n",
    "        gpi_q_network_kwargs=gpi_q_network_kwargs,\n",
    "    )\n",
    "\n",
    "    def _envs_generator(t):\n",
    "        for idx in range(num_test_episodes):\n",
    "            if use_deterministic_transition_with_salts:\n",
    "                yield construct_env_for_specific_task_vec(\n",
    "                    torch.as_tensor([t], device=hyperparameters['device']),\n",
    "                    dict(\n",
    "                        env_specific_random_seed=idx,\n",
    "                        source_xys=psi_info_test['source_xys'],\n",
    "                    ),\n",
    "                )\n",
    "            else:\n",
    "                yield construct_env_for_specific_task_vec(\n",
    "                    torch.as_tensor([t], device=hyperparameters['device']),\n",
    "                    dict(\n",
    "                        source_xys=psi_info_test['source_xys'],\n",
    "                    ),\n",
    "                )\n",
    "    \n",
    "    initial_state = apply_slices(\n",
    "        collect_states_with_generator(\n",
    "            envs_generator=_envs_generator(t),\n",
    "            test_agent=test_agent,\n",
    "            post_rollout_callbacks=post_rollout_callbacks,\n",
    "        ),\n",
    "        (slice(None), 0),\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'return': initial_state['return'],\n",
    "        'undiscounted_return': initial_state['undiscounted_return'],\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import Markdown, display\n",
    "from typing import Union, Callable\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "re_name_ensem_group = re.compile(r'ensemGroup-(?:[0-9]+)-([0-9]+)')\n",
    "re_path_ensem_group = re.compile(r'_eg([0-9]+)_')\n",
    "\n",
    "def _identity_hyp_processor(hyp, psi_info_test, path, psi, t, curr_data, post_rollout_callback_registrator):\n",
    "    return hyp\n",
    "\n",
    "def gather_perf_stats_for_gpi_setting(\n",
    "        *,\n",
    "        settings,\n",
    "        hyp_processor=_identity_hyp_processor,\n",
    "        get_gpi_type,\n",
    "        source_task_vecs: Union[None, torch.Tensor, str, Callable[..., torch.Tensor]],\n",
    "        include_target_task_as_source,\n",
    "        requires_grouped_ensembles,\n",
    "        psi_ckpts_infos_test=psi_ckpts_infos_test,\n",
    "        psi_info_filter=lambda x: True,\n",
    "        num_test_episodes=hyperparameters[\"num_test_episodes\"],\n",
    "    ):\n",
    "\n",
    "    if len(settings) == 0 or len(psi_ckpts_infos_test) == 0:\n",
    "        # Early quitting.\n",
    "        return\n",
    "    \n",
    "    keys_blacklist = [\n",
    "        'name',\n",
    "        'path',\n",
    "        'gpi_type',\n",
    "        'deterministic_transition',\n",
    "        'num_test_episodes',\n",
    "        'use_deterministic_transition_with_salts',\n",
    "        'hyperparameters',\n",
    "        'target_task_vecs_spec',\n",
    "        'target_task_xys',\n",
    "        'target_task_vecs',\n",
    "    ]\n",
    "\n",
    "    def _get_all_gpi_types():\n",
    "        for hyp_orig in settings:\n",
    "            yield get_gpi_type(*hyp_orig)\n",
    "\n",
    "    for psi_info_test in psi_ckpts_infos_test:\n",
    "        if not psi_info_filter(psi_info_test):\n",
    "            continue\n",
    "\n",
    "        if requires_grouped_ensembles:\n",
    "            re_name_match = re_name_ensem_group.search(psi_info_test['name'])\n",
    "            if re_name_match is None:\n",
    "                continue\n",
    "            psi_num_ensemble_groups = int(re_name_match.group(1))\n",
    "            \n",
    "        if 'perf_stats' not in psi_info_test:\n",
    "            psi_info_test['perf_stats'] = dict()\n",
    "        \n",
    "        for path_idx, path in enumerate(psi_info_test['paths']):\n",
    "            if requires_grouped_ensembles:\n",
    "                assert psi_num_ensemble_groups == int(re_path_ensem_group.search(path).group(1))\n",
    "\n",
    "            if not callable(path):\n",
    "                psi = load_usfa_net(path)\n",
    "            curr_psi_stats = dict()\n",
    "\n",
    "            for hyp_orig in settings:\n",
    "                hyp_orig = copy.deepcopy(hyp_orig)\n",
    "                if requires_grouped_ensembles:\n",
    "                    for hi in hyp_orig:\n",
    "                        if 'q_ensemble_reduction_info' in hi:\n",
    "                            hi['q_ensemble_reduction_info']['psi_num_ensemble_groups'] = psi_num_ensemble_groups\n",
    "\n",
    "                gpi_type = get_gpi_type(*hyp_orig)\n",
    "\n",
    "                setting_name = f'{target_task_vecs_spec}_{gpi_type}_{int(use_deterministic_transition_with_salts)}_{num_test_episodes}'\n",
    "\n",
    "                COMPACT_CACHE = '.compact-v2'\n",
    "\n",
    "                curr_data = read_cache_ex_json(\n",
    "                    psi_info=psi_info_test,\n",
    "                    path=path,\n",
    "                    name=psi_info_test['name'],\n",
    "                    setting_name=setting_name,\n",
    "                    hyp=hyp_orig,\n",
    "                    dir_name_suffix=COMPACT_CACHE,\n",
    "                )\n",
    "\n",
    "                if curr_data is None:\n",
    "                    # {{{\n",
    "                    curr_data = read_cache_ex_json(\n",
    "                        psi_info=psi_info_test,\n",
    "                        path=path,\n",
    "                        name=psi_info_test['name'],\n",
    "                        setting_name=setting_name,\n",
    "                        hyp=hyp_orig,\n",
    "                    )\n",
    "                        \n",
    "                    if curr_data is None:\n",
    "                        # {{{\n",
    "                        if load_caches_only:\n",
    "                            continue\n",
    "                        print(psi_info_test['name'], gpi_type)\n",
    "                        curr_data = dict( returns=[], undiscounted_returns=[], )\n",
    "                        for t_idx, t in enumerate(target_task_vecs):\n",
    "\n",
    "                            path_final = (path(t) if callable(path) else path)\n",
    "\n",
    "                            if gpi_type in ['target', 'source', 'source + target']:\n",
    "                                # {{{\n",
    "                                initial_state = apply_slices(\n",
    "                                    collect_states_on_target_tasks(\n",
    "                                        psi_info_test,\n",
    "                                        path_final,\n",
    "                                        gpi_type,\n",
    "                                        num_test_episodes,\n",
    "                                        use_deterministic_transition_with_salts=use_deterministic_transition_with_salts,\n",
    "                                        target_task_vecs=[t],\n",
    "                                    )[0],\n",
    "                                    (slice(None), 0),\n",
    "                                )\n",
    "                                stat = {\n",
    "                                    'return': initial_state['return'],\n",
    "                                    'undiscounted_return': initial_state['undiscounted_return'],\n",
    "                                }\n",
    "                                # }}}\n",
    "                            else:\n",
    "                                # {{{\n",
    "                                post_rollout_callbacks = []\n",
    "                                def _post_rollout_callback_registrator(cb):\n",
    "                                    post_rollout_callbacks.append(cb)\n",
    "\n",
    "                                hyp = hyp_processor(\n",
    "                                    copy.deepcopy(hyp_orig),\n",
    "                                    psi_info_test=psi_info_test,\n",
    "                                    path=path_final,\n",
    "                                    psi=psi,\n",
    "                                    t=t,\n",
    "                                    curr_data=curr_data,\n",
    "                                    post_rollout_callback_registrator=_post_rollout_callback_registrator,\n",
    "                                )\n",
    "\n",
    "                                target_task_vecs_test = torch.as_tensor([t], device=hyperparameters['device'])\n",
    "\n",
    "                                source_task_vecs_test = source_task_vecs\n",
    "                                if not isinstance(source_task_vecs_test, torch.Tensor):\n",
    "                                    if callable(source_task_vecs_test):\n",
    "                                        source_task_vecs_test = source_task_vecs_test(psi_info_test, path_final, t, hyp)\n",
    "                                    elif source_task_vecs_test == 'own_source':\n",
    "                                        source_task_vecs_test = psi_info_test['source_task_vecs']\n",
    "\n",
    "                                if include_target_task_as_source:\n",
    "                                    if source_task_vecs_test is None:\n",
    "                                        source_task_vecs_test = target_task_vecs_test\n",
    "                                    else:\n",
    "                                        source_task_vecs_test = torch.cat([\n",
    "                                            source_task_vecs_test,\n",
    "                                            target_task_vecs_test,\n",
    "                                        ], dim=0)\n",
    "\n",
    "                                stat = get_perf_stats_with_gpi_options(\n",
    "                                    psi_info_test,\n",
    "                                    psi,\n",
    "                                    t,\n",
    "                                    num_test_episodes=num_test_episodes,\n",
    "                                    use_deterministic_transition_with_salts=use_deterministic_transition_with_salts,\n",
    "                                    source_task_vecs=source_task_vecs_test,\n",
    "                                    include_target_task_vec_for_gpi=False,\n",
    "                                    gpi_q_network_kwargs=hyp[0],\n",
    "                                    post_rollout_callbacks=post_rollout_callbacks,\n",
    "                                )\n",
    "                                # }}}\n",
    "\n",
    "                            curr_data['returns'].append(stat['return'].tolist())\n",
    "                            curr_data['undiscounted_returns'].append(stat['undiscounted_return'].tolist())\n",
    "                            \n",
    "                        data_to_save = copy.deepcopy(curr_data)\n",
    "                        data_to_save['name'] = psi_info_test['name']\n",
    "                        data_to_save['path'] = path_final\n",
    "                        data_to_save['gpi_type'] = gpi_type\n",
    "                        data_to_save['num_test_episodes'] = num_test_episodes\n",
    "                        data_to_save['use_deterministic_transition_with_salts'] = use_deterministic_transition_with_salts\n",
    "                        data_to_save['hyperparameters'] = hyperparameters\n",
    "                        data_to_save['target_task_vecs_spec'] = target_task_vecs_spec\n",
    "                        data_to_save['target_task_xys'] = target_task_xys\n",
    "                        data_to_save['target_task_vecs'] = target_task_vecs\n",
    "                        save_cache_ex_json(\n",
    "                            psi_info=psi_info_test,\n",
    "                            path=path,\n",
    "                            name=psi_info_test['name'],\n",
    "                            setting_name=setting_name,\n",
    "                            hyp=hyp_orig,\n",
    "                            data=data_to_save,\n",
    "                        )\n",
    "                        # }}}\n",
    "\n",
    "                    compact_data_to_save = copy.deepcopy(curr_data)\n",
    "                    compact_data_to_save['name'] = psi_info_test['name']\n",
    "                    compact_data_to_save['path'] = path_final\n",
    "                    compact_data_to_save['gpi_type'] = gpi_type\n",
    "                    compact_data_to_save['num_test_episodes'] = num_test_episodes\n",
    "                    compact_data_to_save['use_deterministic_transition_with_salts'] = use_deterministic_transition_with_salts\n",
    "                    compact_data_to_save['hyperparameters'] = hyperparameters\n",
    "                    compact_data_to_save['target_task_vecs_spec'] = target_task_vecs_spec\n",
    "                    compact_data_to_save['target_task_xys'] = target_task_xys\n",
    "                    compact_data_to_save['target_task_vecs'] = target_task_vecs\n",
    "                    for k in [\n",
    "                        'returns',\n",
    "                        'undiscounted_returns',\n",
    "                        'lower_bound_violation_ratio_post_reduction',\n",
    "                        'lower_bound_violation_ratio_post_max',\n",
    "                        'upper_bound_violation_ratio_post_reduction',\n",
    "                        'upper_bound_violation_ratio_post_max',\n",
    "                        'gpi_action_changed_ratio',\n",
    "                    ]:\n",
    "                        if k in compact_data_to_save:\n",
    "                            compact_data_to_save[k] = [\n",
    "                                [\n",
    "                                    np.mean(e, keepdims=True).tolist()\n",
    "                                    for e in d\n",
    "                                ]\n",
    "                                for d in compact_data_to_save[k]\n",
    "                            ]\n",
    "                            curr_data[k] = compact_data_to_save[k]\n",
    "                    save_cache_ex_json(\n",
    "                        psi_info=psi_info_test,\n",
    "                        path=path,\n",
    "                        name=psi_info_test['name'],\n",
    "                        setting_name=setting_name,\n",
    "                        hyp=hyp_orig,\n",
    "                        data=compact_data_to_save,\n",
    "                        dir_name_suffix=COMPACT_CACHE,\n",
    "                    )\n",
    "                    # }}}\n",
    "\n",
    "                for key in curr_data.keys():\n",
    "                    if key in keys_blacklist:\n",
    "                        continue\n",
    "                    assert len(curr_data[key]) == len(target_task_vecs), key\n",
    "\n",
    "                curr_psi_stats[gpi_type] = {\n",
    "                    key: [\n",
    "                        [np.mean(v) for v in e]\n",
    "                        for e in curr_data[key]\n",
    "                    ]\n",
    "                    for key in curr_data.keys()\n",
    "                    if key not in keys_blacklist\n",
    "                }\n",
    "\n",
    "                for key in curr_data.keys():\n",
    "                    if key not in keys_blacklist:\n",
    "                        assert len(curr_psi_stats[gpi_type][key]) == len(target_task_vecs)\n",
    "                    \n",
    "            for gt, d in curr_psi_stats.items():\n",
    "                if gt not in psi_info_test['perf_stats']:\n",
    "                    psi_info_test['perf_stats'][gt] = {\n",
    "                        key: []\n",
    "                        for key in curr_psi_stats[gt].keys()\n",
    "                    }\n",
    "                if any((not isinstance(v, list))\n",
    "                        for v in psi_info_test['perf_stats'][gt].values()):\n",
    "                    continue\n",
    "                    \n",
    "                for key in curr_psi_stats[gt].keys():\n",
    "                    psi_info_test['perf_stats'][gt][key].append(curr_psi_stats[gt][key])\n",
    "                \n",
    "                    \n",
    "                \n",
    "        for gpi_type in _get_all_gpi_types():\n",
    "            if gpi_type not in psi_info_test['perf_stats']:\n",
    "                continue\n",
    "            for key in psi_info_test['perf_stats'][gpi_type].keys():\n",
    "                if isinstance(psi_info_test['perf_stats'][gpi_type][key], list):\n",
    "                    psi_info_test['perf_stats'][gpi_type][key] = np.asarray(psi_info_test['perf_stats'][gpi_type][key]).transpose(1, 0, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def ensure_common_perf_stats_on_target_tasks(psi_info, num_test_episodes):\n",
    "    settings = [\n",
    "        ('target',),\n",
    "        ('source',),\n",
    "        ('source + target',),\n",
    "    ]\n",
    "\n",
    "    def _get_gpi_type(gpi_type):\n",
    "        return gpi_type\n",
    "\n",
    "    gather_perf_stats_for_gpi_setting(\n",
    "        settings=settings,\n",
    "        get_gpi_type=_get_gpi_type,\n",
    "        source_task_vecs=None,\n",
    "        include_target_task_as_source=None,\n",
    "        requires_grouped_ensembles=False,\n",
    "        psi_ckpts_infos_test=[psi_info],\n",
    "        psi_info_filter=lambda x: True,\n",
    "        num_test_episodes=num_test_episodes,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8553708-c82e-44fd-b00c-50464e244dfd",
   "metadata": {},
   "source": [
    "# Comparison of empirical returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_perf_stats2(info):\n",
    "    ensure_common_perf_stats_on_target_tasks(\n",
    "        info, hyperparameters['num_test_episodes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5cef2-c13b-4717-a325-5d547c02dfcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for info in psi_ckpts_infos_test:\n",
    "    ensure_perf_stats2(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7187b4b-edc2-4a26-9c54-63a27b757934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from all.core.state import State, StateArray\n",
    "from alli.core.tensor_util import unsqueeze_and_expand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dce990",
   "metadata": {},
   "source": [
    "## Constrained GPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430a446-08ef-4cab-b746-a2ee6ffbfd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import pickle\n",
    "import hashlib\n",
    "import re\n",
    "import time\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from alli.approximation.optimal_value_bounder import compute_optimal_value_bounds\n",
    "from alli.core.tensor_util import unsqueeze_and_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb75640",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _cgpi_hyp_processor(hyp, psi_info_test, path, psi, t, curr_data, post_rollout_callback_registrator):\n",
    "    gpi_q_network_kwargs = hyp[0]\n",
    "    extra_info = hyp[1]\n",
    "\n",
    "    stat_keys = [\n",
    "        'lower_bound_violation_ratio_post_reduction',\n",
    "        'lower_bound_violation_ratio_post_max',\n",
    "        'upper_bound_violation_ratio_post_reduction',\n",
    "        'upper_bound_violation_ratio_post_max',\n",
    "        'gpi_action_changed_ratio',\n",
    "    ]\n",
    "    for k in stat_keys:\n",
    "        if k not in curr_data:\n",
    "            curr_data[k] = []\n",
    "        curr_data[k].append([])\n",
    "\n",
    "    stacked_data = dict()\n",
    "\n",
    "    def _post_rollout_callback(env, test_agent, states):\n",
    "        #print(len(states), len(stacked_data[list(stacked_data.keys())[0]]))\n",
    "        assert len(states) == len(stacked_data[list(stacked_data.keys())[0]])\n",
    "\n",
    "        for k in stacked_data.keys():\n",
    "            curr_data[k][-1].append(stacked_data[k])\n",
    "            stacked_data[k] = []\n",
    "\n",
    "    post_rollout_callback_registrator(_post_rollout_callback)\n",
    "\n",
    "    def _q_processor_post_reduction(\n",
    "        all_q_values,\n",
    "        states,\n",
    "        actions,\n",
    "    ):\n",
    "        # {{{\n",
    "        assert actions is None\n",
    "\n",
    "        if 'BQ1D4' in psi_info_test['name'] or 'BPDX' in psi_info_test['name'] or 'BPNDX' in psi_info_test['name']:\n",
    "            workaround_source_task_vecs_are_one_hots = False\n",
    "        else:\n",
    "            workaround_source_task_vecs_are_one_hots = False\n",
    "\n",
    "        source_task_vecs = psi_info_test['source_task_vecs']\n",
    "        target_task_vecs = torch.as_tensor([t], device=hyperparameters['device'])\n",
    "\n",
    "        compute_targets = []\n",
    "\n",
    "        if extra_info['reduction_for_bounds'] in ['lm_um', 'lm']:\n",
    "            compute_targets.append('optimal_lower_bounds')\n",
    "            ensemble_reduction_for_source_to_target_values = 'mean'\n",
    "            ensemble_reduction_info_for_source_to_target_values = dict()\n",
    "        else:\n",
    "            # DUMMY\n",
    "            ensemble_reduction_for_source_to_target_values = 'mean'\n",
    "            ensemble_reduction_info_for_source_to_target_values = dict()\n",
    "\n",
    "        if extra_info['reduction_for_bounds'] in ['lm_um', 'um']:\n",
    "            compute_targets.append('optimal_upper_bounds')\n",
    "            ensemble_reduction_for_source_values = 'mean'\n",
    "            ensemble_reduction_info_for_source_values = dict()\n",
    "        else:\n",
    "            # DUMMY\n",
    "            ensemble_reduction_for_source_values = 'mean'\n",
    "            ensemble_reduction_info_for_source_values = dict()\n",
    "\n",
    "        solver = hyperparameters['usfa_constraints']['usfa_con_upper_bound_lp_solver']\n",
    "\n",
    "        bounds = compute_optimal_value_bounds(\n",
    "            psi=psi,\n",
    "            source_task_vecs=source_task_vecs,\n",
    "            states=states,\n",
    "            target_task_vecs=target_task_vecs,\n",
    "            source_task_min_rewards=ReacherWrappedEnv.get_min_rewards(\n",
    "                source_task_vecs,\n",
    "                phi_type='neg_dists_to_source_xys',\n",
    "                method='phi_range',\n",
    "                source_xys=psi_info_test['source_xys'],\n",
    "            ),\n",
    "            discount_factor=hyperparameters['discount_factor'],\n",
    "            max_path_length=hyperparameters['reacher']['max_path_length'],\n",
    "            device=hyperparameters['device'],\n",
    "            solver=solver,\n",
    "            ensemble_reduction_for_source_values=ensemble_reduction_for_source_values,\n",
    "            ensemble_reduction_info_for_source_values=ensemble_reduction_info_for_source_values,\n",
    "            ensemble_reduction_for_source_to_target_values=ensemble_reduction_for_source_to_target_values,\n",
    "            ensemble_reduction_info_for_source_to_target_values=ensemble_reduction_info_for_source_to_target_values,\n",
    "            use_v_values=False,\n",
    "            min_value_adjustment=None,\n",
    "            detach=True,\n",
    "            compute_targets=compute_targets,\n",
    "            workaround_source_task_vecs_are_one_hots=workaround_source_task_vecs_are_one_hots,\n",
    "        )\n",
    "\n",
    "        num_states = np.prod(states.shape)\n",
    "\n",
    "        num_gpi_source_policies_per_state = all_q_values.size(-2)\n",
    "        all_q_values_max = all_q_values.max(len(states.shape)).values\n",
    "\n",
    "        this_data = dict()\n",
    "\n",
    "        updated_all_q_values = all_q_values\n",
    "\n",
    "        if 'optimal_lower_bounds' in compute_targets:\n",
    "            # {{{\n",
    "            assert bounds['optimal_lower_bounds'].size() == (target_task_vecs.size(0), num_states, preset.n_actions)\n",
    "\n",
    "            optimal_lower_bounds_orig = bounds['optimal_lower_bounds'].squeeze(0)\n",
    "            optimal_lower_bounds = unsqueeze_and_expand(\n",
    "                optimal_lower_bounds_orig,\n",
    "                dim=1,\n",
    "                num_repeat=num_gpi_source_policies_per_state,\n",
    "            ).view(*states.shape, num_gpi_source_policies_per_state, preset.n_actions)\n",
    "            assert optimal_lower_bounds.size() == all_q_values.size()\n",
    "\n",
    "            this_data['lower_bound_violation_ratio_post_reduction'] = (\n",
    "                (optimal_lower_bounds > all_q_values).sum().item()\n",
    "                / float(all_q_values.numel())\n",
    "            )\n",
    "            this_data['lower_bound_violation_ratio_post_max'] = (\n",
    "                (optimal_lower_bounds_orig > all_q_values_max).sum().item()\n",
    "                / float(all_q_values_max.numel())\n",
    "            )\n",
    "\n",
    "            updated_all_q_values = torch.maximum(updated_all_q_values, optimal_lower_bounds)\n",
    "            # }}}\n",
    "\n",
    "        if 'optimal_upper_bounds' in compute_targets:\n",
    "            # {{{\n",
    "            assert bounds['optimal_upper_bounds'].size() == (target_task_vecs.size(0), num_states, preset.n_actions)\n",
    "\n",
    "            optimal_upper_bounds_orig = bounds['optimal_upper_bounds'].squeeze(0)\n",
    "            optimal_upper_bounds = unsqueeze_and_expand(\n",
    "                optimal_upper_bounds_orig,\n",
    "                dim=1,\n",
    "                num_repeat=num_gpi_source_policies_per_state,\n",
    "            ).view(*states.shape, num_gpi_source_policies_per_state, preset.n_actions)\n",
    "            assert optimal_upper_bounds.size() == all_q_values.size()\n",
    "\n",
    "            this_data['upper_bound_violation_ratio_post_reduction'] = (\n",
    "                (optimal_upper_bounds < all_q_values).sum().item()\n",
    "                / float(all_q_values.numel())\n",
    "            )\n",
    "            this_data['upper_bound_violation_ratio_post_max'] = (\n",
    "                (optimal_upper_bounds_orig < all_q_values_max).sum().item()\n",
    "                / float(all_q_values_max.numel())\n",
    "            )\n",
    "\n",
    "            updated_all_q_values = torch.minimum(updated_all_q_values, optimal_upper_bounds)\n",
    "            # }}}\n",
    "\n",
    "        gpi_actions = all_q_values_max.argmax(-1)\n",
    "        this_data['gpi_action_changed_ratio'] = (\n",
    "            (updated_all_q_values.max(len(states.shape)).values.argmax(-1) != gpi_actions).sum().item()\n",
    "            / float(gpi_actions.numel())\n",
    "        )\n",
    "\n",
    "        for k, v in this_data.items():\n",
    "            if k not in stacked_data:\n",
    "                stacked_data[k] = []\n",
    "            stacked_data[k].append(v)\n",
    "\n",
    "        return updated_all_q_values\n",
    "\n",
    "        # }}}\n",
    "\n",
    "    gpi_q_network_kwargs['q_processor_post_reduction'] = _q_processor_post_reduction\n",
    "\n",
    "    return (gpi_q_network_kwargs, extra_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8d2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _cgpi_get_gpi_type(gpi_q_network_kwargs, extra_info, gpi_input):\n",
    "    con_info = ''\n",
    "    con_info += 'mP '\n",
    "\n",
    "    if 'targetrand' in gpi_input:\n",
    "        gpi_input += f' ({extra_info[\"num_rands\"]} {extra_info[\"rand_std\"]})'\n",
    "\n",
    "    if extra_info[\"reduction_for_bounds\"] in ['lm_um', 'lm', 'um']:\n",
    "        con_info += f'{extra_info[\"reduction_for_bounds\"]}'\n",
    "    else:\n",
    "        assert False\n",
    "    return f'con ({con_info}) {gpi_input} {gpi_q_network_kwargs[\"q_ensemble_reduction\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = [\n",
    "    (\n",
    "        dict(q_ensemble_reduction='mean',),\n",
    "        dict(reduction_for_bounds='lm_um',),\n",
    "    ),\n",
    "]\n",
    "\n",
    "import functools\n",
    "_get_gpi_type = functools.partial(_cgpi_get_gpi_type, gpi_input='target')\n",
    "\n",
    "source_task_vecs_for_perf = None\n",
    "\n",
    "gather_perf_stats_for_gpi_setting(\n",
    "    settings=settings,\n",
    "    hyp_processor=_cgpi_hyp_processor,\n",
    "    get_gpi_type=_get_gpi_type,\n",
    "    source_task_vecs=source_task_vecs_for_perf,\n",
    "    include_target_task_as_source=True,\n",
    "    requires_grouped_ensembles=False,\n",
    "    psi_ckpts_infos_test=psi_ckpts_infos_test,\n",
    "    psi_info_filter=lambda x: ('ensem' not in x['name']),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2ab1e",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true",
    "tags": []
   },
   "source": [
    "## Rliable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58927d6c",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb5389",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from rliable import library as rly\n",
    "from rliable import metrics\n",
    "from rliable import plot_utils\n",
    "from collections import OrderedDict\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c492c3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_algo_name(name, gpi_type):\n",
    "    return f'{name} ({gpi_type})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581d0ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def gather_min_max_scores(\n",
    "    *,\n",
    "    perf_quantity_info,\n",
    "    plot_infos,\n",
    "    target_task_vecs_filter_np,\n",
    "):\n",
    "    min_scores = None\n",
    "    max_scores = None\n",
    "\n",
    "    pqi = perf_quantity_info\n",
    "    pq = pqi['quantity']\n",
    "\n",
    "    for pi in plot_infos:\n",
    "        name = pi['name']\n",
    "        info_candidates = [\n",
    "            i for i in psi_ckpts_infos_test\n",
    "            if i['name'] == name\n",
    "        ]\n",
    "        if len(info_candidates) == 0:\n",
    "            continue\n",
    "        info = info_candidates[-1]\n",
    "        stats = info['perf_stats']\n",
    "\n",
    "        gpi_types = pi['gpi_types']\n",
    "        for gpi_type in gpi_types:\n",
    "            # Each psi_info_test['perf_stats'][gpi_type][key] has a shape of:\n",
    "            # (num_target_tasks x num_ckpts x num_runs)\n",
    "            curr_stats = stats[gpi_type][pq]\n",
    "            curr_stats = curr_stats[target_task_vecs_filter_np]\n",
    "            num_target_tasks, num_ckpts, num_runs = curr_stats.shape\n",
    "\n",
    "            # Now, num_ckpts becomes the number of runs for Rliable.\n",
    "            curr_scores = curr_stats.transpose(1, 0, 2).reshape(\n",
    "                num_ckpts, num_target_tasks * num_runs,\n",
    "            )\n",
    "            curr_min_scores = curr_scores.min(axis=0)\n",
    "            curr_max_scores = curr_scores.max(axis=0)\n",
    "\n",
    "            if min_scores is None:\n",
    "                min_scores = curr_min_scores\n",
    "            else:\n",
    "                min_scores = np.minimum(min_scores, curr_min_scores)\n",
    "\n",
    "            if max_scores is None:\n",
    "                max_scores = curr_max_scores\n",
    "            else:\n",
    "                max_scores = np.maximum(max_scores, curr_max_scores)\n",
    "\n",
    "    return dict(\n",
    "        min_scores=min_scores,\n",
    "        max_scores=max_scores,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8511f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_score_dict(\n",
    "    *,\n",
    "    perf_quantity_info,\n",
    "    plot_infos,\n",
    "    target_task_vecs_filter_np,\n",
    "    epsilon=1e-3,\n",
    "):\n",
    "    pqi = perf_quantity_info\n",
    "    pq = pqi['quantity']\n",
    "\n",
    "    min_max_scores_info = gather_min_max_scores(\n",
    "        perf_quantity_info=pqi,\n",
    "        plot_infos=plot_infos,\n",
    "        target_task_vecs_filter_np=target_task_vecs_filter_np,\n",
    "    )\n",
    "\n",
    "    score_dict = OrderedDict()\n",
    "\n",
    "    for pi in plot_infos:\n",
    "        name = pi['name']\n",
    "        info_candidates = [\n",
    "            i for i in psi_ckpts_infos_test\n",
    "            if i['name'] == name\n",
    "        ]\n",
    "        if len(info_candidates) == 0:\n",
    "            continue\n",
    "        info = info_candidates[-1]\n",
    "        stats = info['perf_stats']\n",
    "\n",
    "        gpi_types = pi['gpi_types']\n",
    "        for gpi_type in gpi_types:\n",
    "            algo = get_algo_name(name, gpi_type)\n",
    "\n",
    "            # Each psi_info_test['perf_stats'][gpi_type][key] has a shape of:\n",
    "            # (num_target_tasks x num_ckpts x num_runs)\n",
    "            curr_stats = stats[gpi_type][pq]\n",
    "            curr_stats = curr_stats[target_task_vecs_filter_np]\n",
    "            num_target_tasks, num_ckpts, num_runs = curr_stats.shape\n",
    "\n",
    "            # Now, num_ckpts becomes the number of runs for Rliable.\n",
    "            curr_scores = curr_stats.transpose(1, 0, 2).reshape(\n",
    "                num_ckpts, num_target_tasks * num_runs,\n",
    "            )\n",
    "\n",
    "            score_dict[algo] = (curr_scores - min_max_scores_info['min_scores']) / (min_max_scores_info['max_scores'] - min_max_scores_info['min_scores'] + epsilon)\n",
    "            print(pq, algo, score_dict[algo].shape)\n",
    "\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc28a1",
   "metadata": {},
   "source": [
    "### Rliable plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372622bd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "all_possible_algorithms = [\n",
    "    r\"\\textbf{USFAs, CGPI (ours) w/ target}\",\n",
    "    r\"USFAs, GPI w/ source + target\",\n",
    "    r\"USFAs, GPI w/ target\",\n",
    "    r\"USFAs, GPI w/ source\",\n",
    "]\n",
    "color_palette = sns.color_palette('colorblind', n_colors=len(all_possible_algorithms))\n",
    "predefined_colors = dict(zip(all_possible_algorithms, color_palette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be5005",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "# activate latex text rendering\n",
    "rc('text', usetex=True)\n",
    "\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af738372",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _algo_name_converter(name):\n",
    "    if name.endswith(' (source)'):\n",
    "        new_name = r\"USFAs, GPI w/ source\"\n",
    "    if name.endswith(' (target)'):\n",
    "        new_name = r\"USFAs, GPI w/ target\"\n",
    "    if name.endswith(' (source + target)'):\n",
    "        new_name = r\"USFAs, GPI w/ source + target\"\n",
    "    if name.endswith(' (con (mP lm_um) target mean)'):\n",
    "        new_name = r\"\\textbf{USFAs, CGPI (ours) w/ target}\"\n",
    "    if name.endswith(' (con (mP lm_um) source mean)'):\n",
    "        new_name = r\"\\textbf{USFAs, CGPI (ours) w/ source}\"\n",
    "    if name.endswith(' (con (mP lm_um) source + target mean)'):\n",
    "        new_name = r\"\\textbf{USFAs, CGPI (ours) w/ source + target}\"\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b8fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_infos = [\n",
    "    dict(\n",
    "        name='Reacher',\n",
    "        gpi_types=[\n",
    "            'target',\n",
    "            'source',\n",
    "            'source + target',\n",
    "            'con (mP lm_um) target mean',\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "_perf_quantity_infos = [\n",
    "    dict(\n",
    "        quantity='undiscounted_returns', \n",
    "    ),\n",
    "]\n",
    "\n",
    "for task_filter in ['all', 'equal_or_more_negatives']:\n",
    "    score_dict = get_normalized_score_dict(\n",
    "        perf_quantity_info=_perf_quantity_infos[0],\n",
    "        plot_infos=_plot_infos,\n",
    "        target_task_vecs_filter_np=all_target_task_vecs_filters_np[task_filter],\n",
    "        epsilon=1e-3,\n",
    "    )\n",
    "\n",
    "    score_dict = OrderedDict([\n",
    "        (_algo_name_converter(k), v)\n",
    "        for k, v in score_dict.items()\n",
    "    ])\n",
    "\n",
    "    algorithms = [\n",
    "        r\"USFAs, GPI w/ source\",\n",
    "        r\"USFAs, GPI w/ target\",\n",
    "        r\"USFAs, GPI w/ source + target\",\n",
    "        r\"\\textbf{USFAs, CGPI (ours) w/ target}\",\n",
    "    ]\n",
    "    algorithms = list(reversed(algorithms))\n",
    "\n",
    "    score_dict = OrderedDict([\n",
    "        (k, score_dict[k])\n",
    "        for k in algorithms\n",
    "    ])\n",
    "\n",
    "    # Load ALE scores as a dictionary mapping algorithms to their human normalized\n",
    "    # score matrices, each of which is of size `(num_runs x num_games)`.\n",
    "    aggregate_func = lambda x: np.array([\n",
    "        metrics.aggregate_median(x),\n",
    "        metrics.aggregate_iqm(x),\n",
    "        metrics.aggregate_mean(x),\n",
    "        metrics.aggregate_optimality_gap(x),\n",
    "    ])\n",
    "\n",
    "    rep = 500\n",
    "    rep = 50000\n",
    "\n",
    "\n",
    "    aggregate_scores, aggregate_score_cis = rly.get_interval_estimates(\n",
    "        score_dict, aggregate_func, reps=rep)\n",
    "    fig, axes = plot_utils.plot_interval_estimates(\n",
    "        aggregate_scores, aggregate_score_cis,\n",
    "        metric_names=[\n",
    "            'Median',\n",
    "            'IQM',\n",
    "            'Mean',\n",
    "            'Optimality Gap',\n",
    "        ],\n",
    "        colors=predefined_colors,\n",
    "        algorithms=algorithms, xlabel='Normalized Score', xlabel_y_coordinate=-0.3)\n",
    "\n",
    "    display(fig)\n",
    "\n",
    "    fig.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d6035",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "_plot_infos = [\n",
    "    dict(\n",
    "        name='Reacher',\n",
    "        gpi_types=[\n",
    "            'target',\n",
    "            'source',\n",
    "            'source + target',\n",
    "            'con (mP lm_um) target mean',\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "_perf_quantity_infos = [\n",
    "    dict(\n",
    "        quantity='undiscounted_returns', \n",
    "    ),\n",
    "]\n",
    "\n",
    "for task_filter in ['all', 'equal_or_more_negatives']:\n",
    "    score_dict = get_normalized_score_dict(\n",
    "        perf_quantity_info=_perf_quantity_infos[0],\n",
    "        plot_infos=_plot_infos,\n",
    "        target_task_vecs_filter_np=all_target_task_vecs_filters_np[task_filter],\n",
    "        epsilon=1e-3,\n",
    "    )\n",
    "\n",
    "    score_dict = OrderedDict([\n",
    "        (_algo_name_converter(k), v)\n",
    "        for k, v in score_dict.items()\n",
    "    ])\n",
    "    print(list(score_dict.keys()))\n",
    "\n",
    "    algorithms = [\n",
    "        r\"USFAs, GPI w/ source\",\n",
    "        r\"USFAs, GPI w/ target\",\n",
    "        r\"USFAs, GPI w/ source + target\",\n",
    "        r\"\\textbf{USFAs, CGPI (ours) w/ target}\",\n",
    "    ]\n",
    "\n",
    "    score_dict = OrderedDict([\n",
    "        (k, score_dict[k])\n",
    "        for k in algorithms\n",
    "    ])\n",
    "\n",
    "    # Load ALE scores as a dictionary mapping algorithms to their human normalized\n",
    "    # score matrices, each of which is of size `(num_runs x num_games)`.\n",
    "\n",
    "    # Human normalized score thresholds\n",
    "    thresholds = np.linspace(0.0, 1.0, 5)\n",
    "    thresholds = np.linspace(0.0, 1.0, 100)\n",
    "    thresholds = np.linspace(0.0, 1.0, 20)\n",
    "    score_distributions, score_distributions_cis = rly.create_performance_profile(\n",
    "        score_dict, thresholds)\n",
    "    # Plot score distributions\n",
    "    fig, ax = plt.subplots(ncols=1, figsize=(4.9, 3.5))\n",
    "    plot_utils.plot_performance_profiles(\n",
    "        score_distributions, thresholds,\n",
    "        performance_profile_cis=score_distributions_cis,\n",
    "        colors=predefined_colors,\n",
    "        xlabel=r'Normalized Score $(\\tau)$',\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    display(fig)\n",
    "\n",
    "    fig.clf()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python [conda env:psfs]",
   "language": "python",
   "name": "conda-env-psfs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
